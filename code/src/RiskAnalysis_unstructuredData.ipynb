{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR4fEk385A5X",
        "outputId": "b0290a98-3373-401c-de78-2bc78bc22fa7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOGLHLFx5FRn",
        "outputId": "709bd52d-d869-45b3-cb3e-07bddfdd4e81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEDy66qi3rrO",
        "outputId": "37b67101-0e31-4121-bfb1-6484a78eb6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/sample_data/unstructured_text\n",
            "Processed data saved to Risk_analysis_unstructured_output.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import chardet\n",
        "import re\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import requests\n",
        "\n",
        "def detect_encoding(file_path):\n",
        "    \"\"\"Detect file encoding to prevent UnicodeDecodeError\"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        raw_data = f.read()\n",
        "        result = chardet.detect(raw_data)\n",
        "    return result[\"encoding\"]\n",
        "\n",
        "def extract_transactions(file_path):\n",
        "    \"\"\"Extract structured data from an unstructured text file\"\"\"\n",
        "    encoding = detect_encoding(file_path)\n",
        "\n",
        "    with open(file_path, \"r\", encoding=encoding, errors=\"replace\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    transactions = []\n",
        "    for line in lines:\n",
        "        # Extract transaction details using regex patterns\n",
        "        amount_match = re.search(r\"\\$?(\\d{1,3}(?:[,\\.]\\d{3})*(?:\\.\\d{1,2})?)\", line)\n",
        "        name_match = re.findall(r\"\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\b\", line)\n",
        "\n",
        "        amount = float(amount_match.group(1).replace(\",\", \"\")) if amount_match else None\n",
        "        payer = name_match[0] if len(name_match) > 0 else \"Unknown\"\n",
        "        receiver = name_match[1] if len(name_match) > 1 else \"Unknown\"\n",
        "\n",
        "        transactions.append({\n",
        "            \"transaction_details\": line.strip(),\n",
        "            \"payers_name\": payer,\n",
        "            \"receiver_name\": receiver,\n",
        "            \"amount\": amount\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(transactions)\n",
        "\n",
        "def extract_entities(text, nlp):\n",
        "    \"\"\"Extract relevant entities (ORG, PERSON) using SpaCy\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"PERSON\"]]\n",
        "\n",
        "def enrich_entity(name):\n",
        "    \"\"\"Fetch additional details about an entity from OpenCorporates API\"\"\"\n",
        "    try:\n",
        "        search_url = f\"https://api.opencorporates.com/v0.4/companies/search?q={name}\"\n",
        "        response = requests.get(search_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        return {\"name\": name, \"error\": \"No data found\"}\n",
        "    except requests.exceptions.RequestException:\n",
        "        return {\"name\": name, \"error\": \"API request failed\"}\n",
        "\n",
        "def detect_anomalies(data):\n",
        "    \"\"\"Detect anomalies in transaction amounts using Isolation Forest\"\"\"\n",
        "    model = IsolationForest(contamination=0.05)\n",
        "    data['anomaly_score'] = model.fit_predict(data[['amount']].fillna(0))\n",
        "    return data\n",
        "\n",
        "def classify_entity(name):\n",
        "    \"\"\"Classify entity type based on keywords\"\"\"\n",
        "    categories = {\n",
        "        \"corporation\": [\"Inc\", \"Corp\", \"LLC\", \"Capital\", \"Partners\"],\n",
        "        \"non-profit\": [\"Foundation\", \"Charity\", \"Save\", \"Children\"],\n",
        "        \"government\": [\"Department\", \"Agency\", \"Bureau\"]\n",
        "    }\n",
        "    for category, keywords in categories.items():\n",
        "        if any(word in name for word in keywords):\n",
        "            return category\n",
        "    return \"unknown\"\n",
        "\n",
        "def assign_risk_score(entity_data):\n",
        "    \"\"\"Assign a risk score based on entity classification and anomaly detection\"\"\"\n",
        "    risk_score = 0\n",
        "    if entity_data.get(\"category\", \"\") == \"shell company\":\n",
        "        risk_score += 5\n",
        "    if entity_data.get(\"anomaly_score\", 0) == -1:\n",
        "        risk_score += 3\n",
        "    return risk_score\n",
        "\n",
        "def main(file_path):\n",
        "    \"\"\"Main function to process unstructured financial transaction data\"\"\"\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "\n",
        "    # Load English NLP model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Extract transactions from the text file\n",
        "    df = extract_transactions(file_path)\n",
        "\n",
        "    # Extract entities from transaction details\n",
        "    df['entities'] = df.apply(lambda x: extract_entities(str(x['transaction_details']), nlp)\n",
        "                              + [x['payers_name'], x['receiver_name']], axis=1)\n",
        "\n",
        "    # Enrich entity information\n",
        "    enriched_data = []\n",
        "    for entity in df['entities'].explode().dropna().unique():\n",
        "        entity_info = enrich_entity(entity)\n",
        "        entity_info['name'] = entity\n",
        "        entity_info['category'] = classify_entity(entity)\n",
        "        entity_info['risk_score'] = assign_risk_score(entity_info)\n",
        "        enriched_data.append(entity_info)\n",
        "\n",
        "    # Merge enriched data with original dataset\n",
        "    enriched_df = pd.DataFrame(enriched_data)\n",
        "    final_df = df.explode('entities').merge(enriched_df, left_on='entities', right_on='name', how='left')\n",
        "\n",
        "    # Detect anomalies\n",
        "    final_df = detect_anomalies(final_df)\n",
        "\n",
        "    # Save output to an Excel file\n",
        "    output_file = \"Risk_analysis_unstructured_output.xlsx\"\n",
        "    final_df.to_excel(output_file, index=False)\n",
        "    print(f\"Processed data saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(\"/content/sample_data/unstructured_text\")\n"
      ]
    }
  ]
}